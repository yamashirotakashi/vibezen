#!/usr/bin/env python3
"""
VIBEZEN é«˜é€Ÿãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
é‡è¦ãªæ©Ÿèƒ½ã®æ€§èƒ½ã‚’è¿…é€Ÿã«æ¸¬å®š
"""

import time
import psutil
import sys
from pathlib import Path
import subprocess
import json
from datetime import datetime

def quick_benchmark():
    """é«˜é€Ÿãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
    print("âš¡ VIBEZEN é«˜é€Ÿãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)
    
    results = {
        'timestamp': datetime.now().isoformat(),
        'tests': {}
    }
    
    # Test 1: å“è³ªãƒã‚§ãƒƒã‚¯é€Ÿåº¦ï¼ˆå°è¦æ¨¡ï¼‰
    print("\nğŸ” Test 1: å“è³ªãƒã‚§ãƒƒã‚¯é€Ÿåº¦æ¸¬å®š")
    test_projects = [
        "/mnt/c/Users/tky99/dev/vibezen",
        "/mnt/c/Users/tky99/dev/techbookanalytics"
    ]
    
    for project in test_projects:
        if not Path(project).exists():
            continue
            
        project_name = Path(project).name
        print(f"  ğŸ“ {project_name}...")
        
        try:
            start_time = time.perf_counter()
            start_memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            # å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆçŸ­ç¸®ï¼‰
            result = subprocess.run([
                sys.executable, 
                f"{project}/vibezen_quality_check.py"
            ], capture_output=True, text=True, timeout=15, cwd=project)
            
            end_time = time.perf_counter()
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            execution_time = end_time - start_time
            memory_delta = end_memory - start_memory
            
            results['tests'][f'quality_check_{project_name}'] = {
                'execution_time': execution_time,
                'memory_delta_mb': memory_delta,
                'success': result.returncode == 0,
                'output_size': len(result.stdout)
            }
            
            print(f"    âœ… å®Ÿè¡Œæ™‚é–“: {execution_time:.3f}ç§’")
            print(f"    ğŸ“Š ãƒ¡ãƒ¢ãƒªå¢—åŠ : {memory_delta:.1f}MB")
            
        except subprocess.TimeoutExpired:
            print(f"    â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (15ç§’)")
            results['tests'][f'quality_check_{project_name}'] = {
                'timeout': True,
                'execution_time': 15.0
            }
        except Exception as e:
            print(f"    âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            results['tests'][f'quality_check_{project_name}'] = {
                'error': str(e)
            }
    
    # Test 2: VZã‚³ãƒãƒ³ãƒ‰é€Ÿåº¦
    print("\nğŸš€ Test 2: [VZ]ã‚³ãƒãƒ³ãƒ‰é€Ÿåº¦æ¸¬å®š")
    
    try:
        start_time = time.perf_counter()
        
        # VZã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆçŸ­ç¸®ï¼‰
        result = subprocess.run([
            sys.executable, 
            "/mnt/c/Users/tky99/dev/vibezen/scripts/simple_vz_test.py", 
            "vz"
        ], capture_output=True, text=True, timeout=20, 
        cwd="/mnt/c/Users/tky99/dev/vibezen")
        
        end_time = time.perf_counter()
        execution_time = end_time - start_time
        
        results['tests']['vz_command'] = {
            'execution_time': execution_time,
            'success': result.returncode == 0,
            'output_size': len(result.stdout)
        }
        
        print(f"  âœ… å®Ÿè¡Œæ™‚é–“: {execution_time:.3f}ç§’")
        
    except subprocess.TimeoutExpired:
        print(f"  â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (20ç§’)")
        results['tests']['vz_command'] = {
            'timeout': True,
            'execution_time': 20.0
        }
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        results['tests']['vz_command'] = {
            'error': str(e)
        }
    
    # Test 3: ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
    print("\nğŸ“ Test 3: ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¸¬å®š")
    
    try:
        start_time = time.perf_counter()
        
        # è¤‡æ•°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®Pythonãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚«ã‚¦ãƒ³ãƒˆ
        total_files = 0
        for project in test_projects:
            if Path(project).exists():
                py_files = list(Path(project).rglob("*.py"))
                total_files += len(py_files[:50])  # æœ€å¤§50ãƒ•ã‚¡ã‚¤ãƒ«ã¾ã§
        
        end_time = time.perf_counter()
        processing_time = end_time - start_time
        throughput = total_files / processing_time if processing_time > 0 else 0
        
        results['tests']['file_throughput'] = {
            'total_files': total_files,
            'processing_time': processing_time,
            'throughput_files_per_sec': throughput
        }
        
        print(f"  ğŸ“Š å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")
        print(f"  âš¡ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {throughput:.1f} files/sec")
        
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        results['tests']['file_throughput'] = {
            'error': str(e)
        }
    
    # çµæœåˆ†æ
    print("\nğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ")
    print("-" * 30)
    
    total_time = sum(
        test.get('execution_time', 0) 
        for test in results['tests'].values() 
        if 'execution_time' in test
    )
    
    successful_tests = sum(
        1 for test in results['tests'].values() 
        if test.get('success', False)
    )
    
    total_tests = len(results['tests'])
    success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
    
    print(f"âœ… æˆåŠŸç‡: {success_rate:.1f}% ({successful_tests}/{total_tests})")
    print(f"â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {total_time:.3f}ç§’")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
    if success_rate >= 80 and total_time < 10:
        grade = "ğŸŒŸ A"
        comment = "å„ªç§€ï¼é«˜é€Ÿã‹ã¤å®‰å®šã—ãŸå‡¦ç†"
    elif success_rate >= 60 and total_time < 20:
        grade = "âœ… B"
        comment = "è‰¯å¥½ã€‚å®Ÿç”¨çš„ãªæ€§èƒ½"
    elif success_rate >= 40:
        grade = "ğŸŸ¡ C"
        comment = "è¦æ³¨æ„ã€‚æœ€é©åŒ–ãŒå¿…è¦"
    else:
        grade = "ğŸ”´ D"
        comment = "å•é¡Œã‚ã‚Šã€‚å¤§å¹…ãªæ”¹å–„ãŒå¿…è¦"
    
    print(f"\nğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡: {grade}")
    print(f"   {comment}")
    
    # çµæœä¿å­˜
    output_file = "/mnt/c/Users/tky99/dev/vibezen/quick_benchmark_result.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ çµæœä¿å­˜: {output_file}")
    
    return {
        'grade': grade,
        'success_rate': success_rate,
        'total_time': total_time,
        'results': results
    }

if __name__ == "__main__":
    quick_benchmark()