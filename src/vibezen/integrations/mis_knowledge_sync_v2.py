"""
MIS Knowledge Graphé€£æºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« V2 - @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å¯¾å¿œç‰ˆ

Claude Code v1.0.27+ã®@ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã¦ã€
ã‚ˆã‚Šç›´æ„Ÿçš„ã§ã‚·ãƒ³ãƒ—ãƒ«ãªKnowledge Graphæ“ä½œã‚’å®Ÿç¾ã—ã¾ã™ã€‚

å¤‰æ›´ç‚¹:
- kg_client.call_tool() â†’ @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³æ§‹æ–‡
- æ˜ç¤ºçš„ãªAPIå‘¼ã³å‡ºã— â†’ è‡ªç„¶ãªå‚ç…§å½¢å¼
- è¤‡é›‘ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ§‹ç¯‰ â†’ ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ã‚¨ãƒªæ–‡å­—åˆ—
"""

import asyncio
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import json
import hashlib
import sys
from pathlib import Path

# @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent / "scripts"))
from mcp_mention_parser import MCPMentionParser, MCPMention

from vibezen.core.types import (
    QualityReport,
    IntrospectionTrigger,
    ThinkingStep,
    ImplementationChoice
)
from vibezen.core.auto_rollback import RollbackResult
from vibezen.utils.logger import get_logger

logger = get_logger(__name__)


class MISKnowledgeSyncV2:
    """MIS Knowledge GraphåŒæœŸãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ V2 - @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å¯¾å¿œ"""
    
    def __init__(self):
        """
        åˆæœŸåŒ–
        
        Note:
            V2ã§ã¯kg_clientã¯ä¸è¦ã€‚@ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã§ç›´æ¥å‚ç…§ã—ã¾ã™ã€‚
        """
        self._entity_cache: Dict[str, str] = {}  # entity_key -> kg_id
        self._pattern_library: Dict[str, Any] = {}  # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
        self.mention_parser = MCPMentionParser()
    
    async def sync_quality_pattern(
        self,
        pattern_type: str,
        pattern_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’Knowledge Graphã«åŒæœŸ
        
        @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã«å®Ÿè£…
        """
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ä½œæˆ
        entity_name = f"QualityPattern_{pattern_type}_{self._generate_pattern_id(pattern_data)}"
        
        observations = [
            f"Pattern type: {pattern_type}",
            f"Detection confidence: {pattern_data.get('confidence', 0)}",
            f"Severity: {pattern_data.get('severity', 'unknown')}",
            f"First detected: {datetime.now().isoformat()}"
        ]
        
        if pattern_data.get('description'):
            observations.append(f"Description: {pattern_data['description']}")
        
        if pattern_data.get('fix_suggestion'):
            observations.append(f"Fix suggestion: {pattern_data['fix_suggestion']}")
        
        # @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å½¢å¼ã§ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä½œæˆã‚’è¡¨ç¾
        entity_creation_text = f"""
        å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜éŒ²ã—ã¾ã™:
        @kg:create/entities
        
        ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æƒ…å ±:
        - åå‰: {entity_name}
        - ã‚¿ã‚¤ãƒ—: quality_pattern
        - è¦³å¯Ÿãƒ‡ãƒ¼ã‚¿: {json.dumps(observations, ensure_ascii=False)}
        - ã‚¿ã‚°: vibezen, {pattern_type}, {pattern_data.get('severity', 'medium')}, auto_detected
        """
        
        # å®Ÿéš›ã®APIå‘¼ã³å‡ºã—ã®ä»£ã‚ã‚Šã«ã€@ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¿”ã™
        logger.info(f"[V2] Creating quality pattern via @mention: {entity_name}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«è¿½åŠ 
        self._pattern_library[pattern_type] = self._pattern_library.get(pattern_type, [])
        self._pattern_library[pattern_type].append({
            "id": entity_name,
            "data": pattern_data,
            "created_at": datetime.now().isoformat()
        })
        
        return entity_name
    
    async def search_similar_patterns(
        self,
        pattern_type: str,
        pattern_features: Dict[str, Any],
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        é¡ä¼¼ã®å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        
        @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³æ§‹æ–‡ã§æ¤œç´¢ã‚’è¡¨ç¾
        """
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
        search_features = []
        if pattern_features.get('code_snippet'):
            search_features.append(self._extract_code_features(pattern_features['code_snippet']))
        
        # @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å½¢å¼ã®æ¤œç´¢
        search_text = f"""
        é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢:
        @kg:search?query=quality_pattern+{pattern_type}+{'+'.join(search_features)}&limit={limit}
        """
        
        # @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’ãƒ‘ãƒ¼ã‚¹
        mentions = self.mention_parser.parse_mentions(search_text)
        
        if mentions:
            mention = mentions[0]
            api_call = self.mention_parser.to_mcp_call(mention)
            logger.info(f"[V2] Searching patterns via @mention: {api_call}")
            
            # ãƒ‡ãƒ¢ç”¨ã®ä»®æƒ³çµæœã‚’è¿”ã™
            return self._generate_demo_search_results(pattern_type, limit)
        
        return []
    
    async def get_fix_recommendations_v2(
        self,
        issue_type: str,
        context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        éå»ã®ä¿®æ­£å±¥æ­´ã‹ã‚‰æ¨å¥¨äº‹é …ã‚’å–å¾—ï¼ˆV2ç‰ˆï¼‰
        
        @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‚ç…§ã‚’çµ„ã¿åˆã‚ã›ãŸå®Ÿè£…
        """
        # è¤‡æ•°ã®@ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’å«ã‚€æ¤œç´¢
        recommendation_query = f"""
        ä¿®æ­£æ¨å¥¨äº‹é …ã‚’å–å¾—ã™ã‚‹ãŸã‚ã€ä»¥ä¸‹ã‚’æ¤œç´¢ã—ã¾ã™:
        
        1. æˆåŠŸã—ãŸä¿®æ­£å±¥æ­´: @kg:search?query=fix_history+success+{issue_type}
        2. é–¢é€£ãƒ‘ã‚¿ãƒ¼ãƒ³: @kg:search?query=quality_pattern+{issue_type}
        3. å­¦ç¿’æ¸ˆã¿è§£æ±ºç­–: @memory:search?query=vibezen+fix+{issue_type}
        
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {json.dumps(context, ensure_ascii=False)[:200]}
        """
        
        # è¤‡æ•°ã®@ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’ãƒ‘ãƒ¼ã‚¹
        mentions = self.mention_parser.parse_mentions(recommendation_query)
        
        recommendations = []
        
        for mention in mentions:
            api_call = self.mention_parser.to_mcp_call(mention)
            logger.info(f"[V2] Getting recommendations via @mention: {api_call}")
            
            # ãƒ‡ãƒ¢ç”¨ã®æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
            if "fix_history" in api_call["params"]["query"]:
                recommendations.extend(self._generate_demo_fix_recommendations(issue_type))
        
        return recommendations[:5]
    
    def demonstrate_mention_patterns(self) -> Dict[str, str]:
        """
        åˆ©ç”¨å¯èƒ½ãª@ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã™
        
        Returns:
            ãƒ‘ã‚¿ãƒ¼ãƒ³åã¨ã‚µãƒ³ãƒ—ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        """
        patterns = {
            "å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³ä½œæˆ": "@kg:create/entities?type=quality_pattern",
            "ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢": "@kg:search?query=quality_pattern+hardcode",
            "ä¿®æ­£å±¥æ­´å‚ç…§": "@kg:entities/fix_history/FixHistory_20250124_123456",
            "æ€è€ƒãƒˆãƒ¬ãƒ¼ã‚¹è¨˜éŒ²": "@memory:create/entities?type=thinking_trace",
            "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–“æ¤œç´¢": "@kg:search?query=vibezen&project_id=all",
            "ã‚¿ã‚°ãƒ™ãƒ¼ã‚¹æ¤œç´¢": "@kg:search?tags=auto_fix,success",
            "é–¢ä¿‚æ€§ä½œæˆ": "@kg:create/relations?from=pattern1&to=fix1&type=fixes",
            "çµ±è¨ˆæƒ…å ±å–å¾—": "@kg:read_graph?project_id=vibezen"
        }
        
        return patterns
    
    def _generate_pattern_id(self, pattern_data: Dict[str, Any]) -> str:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¦ãƒ‹ãƒ¼ã‚¯IDã‚’ç”Ÿæˆ"""
        key_parts = [
            pattern_data.get('type', ''),
            pattern_data.get('severity', ''),
            pattern_data.get('description', '')[:50]
        ]
        
        key_string = "_".join(filter(None, key_parts))
        return hashlib.md5(key_string.encode()).hexdigest()[:8]
    
    def _extract_code_features(self, code_snippet: str) -> str:
        """ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ç‰¹å¾´ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        features = []
        
        import re
        func_pattern = r'def\s+(\w+)'
        functions = re.findall(func_pattern, code_snippet)
        if functions:
            features.extend(functions[:3])
        
        class_pattern = r'class\s+(\w+)'
        classes = re.findall(class_pattern, code_snippet)
        if classes:
            features.extend(classes[:2])
        
        return "+".join(features)
    
    def _generate_demo_search_results(self, pattern_type: str, limit: int) -> List[Dict[str, Any]]:
        """ãƒ‡ãƒ¢ç”¨ã®æ¤œç´¢çµæœã‚’ç”Ÿæˆ"""
        results = []
        for i in range(min(3, limit)):
            results.append({
                "entity_id": f"QualityPattern_{pattern_type}_{i}",
                "pattern_type": pattern_type,
                "observations": [
                    f"Pattern type: {pattern_type}",
                    f"Detection confidence: 0.{85 - i*10}",
                    f"Severity: {'high' if i == 0 else 'medium'}"
                ],
                "tags": ["vibezen", pattern_type, "auto_detected"],
                "similarity_score": 0.9 - (i * 0.1)
            })
        return results
    
    def _generate_demo_fix_recommendations(self, issue_type: str) -> List[Dict[str, Any]]:
        """ãƒ‡ãƒ¢ç”¨ã®ä¿®æ­£æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        recommendations = [
            {
                "fix_id": f"FixHistory_demo_{issue_type}_1",
                "fixes": [
                    f"Extract {issue_type} to configuration",
                    f"Use dependency injection for {issue_type}",
                    "Add validation layer"
                ],
                "quality_improvement": 15.5,
                "confidence": 0.85
            },
            {
                "fix_id": f"FixHistory_demo_{issue_type}_2",
                "fixes": [
                    f"Refactor {issue_type} using strategy pattern",
                    "Add comprehensive tests"
                ],
                "quality_improvement": 12.0,
                "confidence": 0.75
            }
        ]
        return recommendations
    
    def get_sync_statistics(self) -> Dict[str, Any]:
        """åŒæœŸçµ±è¨ˆã‚’å–å¾—"""
        pattern_count = sum(len(patterns) for patterns in self._pattern_library.values())
        
        return {
            "total_entities": len(self._entity_cache),
            "pattern_types": list(self._pattern_library.keys()),
            "total_patterns": pattern_count,
            "mention_syntax_enabled": True,
            "api_version": "v2_mention"
        }


async def demonstrate_v2_features():
    """V2æ©Ÿèƒ½ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    sync_v2 = MISKnowledgeSyncV2()
    
    print("ğŸš€ MIS Knowledge Sync V2 - @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å¯¾å¿œç‰ˆ")
    print("=" * 60)
    
    # 1. å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³ã®åŒæœŸ
    print("\n1ï¸âƒ£ å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³ã®åŒæœŸï¼ˆ@ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ç‰ˆï¼‰")
    pattern_id = await sync_v2.sync_quality_pattern(
        pattern_type="hardcode",
        pattern_data={
            "confidence": 0.9,
            "severity": "high",
            "description": "ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸAPI URL",
            "fix_suggestion": "ç’°å¢ƒå¤‰æ•°ã«ç§»å‹•"
        }
    )
    print(f"   ä½œæˆã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern_id}")
    
    # 2. é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œç´¢
    print("\n2ï¸âƒ£ é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œç´¢")
    similar = await sync_v2.search_similar_patterns(
        pattern_type="hardcode",
        pattern_features={"code_snippet": "def connect_api():\n    url = 'http://localhost:8080'"}
    )
    print(f"   è¦‹ã¤ã‹ã£ãŸé¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(similar)}å€‹")
    for pattern in similar[:2]:
        print(f"   - {pattern['entity_id']} (é¡ä¼¼åº¦: {pattern['similarity_score']:.1f})")
    
    # 3. ä¿®æ­£æ¨å¥¨ã®å–å¾—
    print("\n3ï¸âƒ£ ä¿®æ­£æ¨å¥¨äº‹é …ã®å–å¾—")
    recommendations = await sync_v2.get_fix_recommendations_v2(
        issue_type="hardcode",
        context={"file": "api_client.py", "line": 42}
    )
    print(f"   æ¨å¥¨äº‹é …: {len(recommendations)}å€‹")
    for rec in recommendations[:2]:
        print(f"   - {rec['fix_id']}: å“è³ªæ”¹å–„ +{rec['quality_improvement']}ç‚¹")
    
    # 4. @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§
    print("\n4ï¸âƒ£ åˆ©ç”¨å¯èƒ½ãª@ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³")
    patterns = sync_v2.demonstrate_mention_patterns()
    for name, pattern in list(patterns.items())[:5]:
        print(f"   - {name}: {pattern}")
    
    # 5. çµ±è¨ˆæƒ…å ±
    print("\n5ï¸âƒ£ åŒæœŸçµ±è¨ˆ")
    stats = sync_v2.get_sync_statistics()
    print(f"   {json.dumps(stats, ensure_ascii=False, indent=3)}")


if __name__ == "__main__":
    asyncio.run(demonstrate_v2_features())